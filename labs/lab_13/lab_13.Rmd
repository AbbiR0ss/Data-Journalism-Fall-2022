---
title: "lab_12"
author: "derek willis"
date: "11/25/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

* Our usual libraries for working with data, plus rvest and possibly readxl for reading Excel files.

## Load libraries and establish settings

**Task** Create a codeblock and load appropriate packages and settings for this lab.

```{r}
# Turn off scientific notation
options(scipen=999)

library(readxl)
library(tidyverse)
library(janitor)
library(rvest)
library(lubridate)
```

## Getting the Data

We're continuing our contrasting of the 2022 and 2018 elections, but this time we're switching to a different state: Utah. Utah had an unusual Senate election in 2022: Democrats did not nominate a candidate to run against incumbent Republican Mike Lee and instead endorsed an independent, Evan McMullin, in the race. Broadly, we want to dig into the differences between the 2022 Senate results and the 2018 Senate race, when Republican Mitt Romney defeated Democrat Jenny Wilson.

Let's start with the 2022 results. You'll need to locate and scrape the 2022 county-level results for the U.S. Senate race from the Utah Elections site (https://electionresults.utah.gov/elections/). Utah has 29 counties, so if you don't have at least 29 rows in your dataframe, you've scraped the wrong page.

**Task** Scrape the county-level results for the U.S. Senate race in 2022, which can be found at https://electionresults.utah.gov/elections/, into a dataframe. You will need to make sure that you have clean headers, which may involve renaming them, and you will need to remove the total row. Make sure that the columns containing votes are numeric.

```{r}
utah_results <- "https://electionresults.utah.gov/elections/countyCount/451556070"
```

```{r}
senate_results <- utah_results %>%
  read_html() %>%
  html_table()

# show the dataframe
senate_results
```

```{r}
senate_results <- utah_results %>%
  read_html() %>%
  html_table()
# Just keep the first dataframe in our list

senate_results <- senate_results[[1]]

# show the dataframe
senate_results
```
```{r}
# Read in all html from table, get the HTML table.
senate_results <- utah_results %>%
  read_html() %>%
  html_table()

# Standardize column headers, remove last row

senate_results <- senate_results[[1]] %>%
  clean_names() %>%
  rename(county = 1, korb = 2, mcmullin = 3, hansen=4, hamblin=5, seguin=6, lee=7, williams=8) %>%
  slice(-2) %>%
  mutate(korb = as.numeric(gsub(",","", korb))) %>%
  mutate(mcmullin = as.numeric(gsub(",","", mcmullin))) %>%
  mutate(hansen = as.numeric(gsub(",","", hansen))) %>%
  mutate(hamblin = as.numeric(gsub(",","", hamblin))) %>%
  mutate(seguin = as.numeric(gsub(",","", seguin))) %>%
  mutate(lee = as.numeric(gsub(",","", lee))) %>%
  mutate(williams = as.numeric(gsub(",","", williams)))
# show the dataframe
senate_results

```

```{r}
senate_results <- senate_results %>%
  slice(-1)

senate_results
```

Next, we'll get the 2018 results. Unlike the 2022 results, these are stored in an Excel file located here: https://elections.utah.gov/Media/Default/2018%20Election/2018%20General%20Election%20Canvass.xlsx. You can choose how to get the U.S. Senate results - whether you download and save the file in this lab_13 folder (we did this in pre_lab_12) or whether you download it manually and create a CSV file from the Senate results sheet in this directory. Like the 2022 results, you'll want to make a dataframe with clean headers, no total row and numeric columns for the votes.

**Task** Get the county-level results for the U.S. Senate race in 2018, which can be found at https://elections.utah.gov/Media/Default/2018%20Election/2018%20General%20Election%20Canvass.xlsx, and turn them into a dataframe. You will need to make sure that you have clean headers, which may involve renaming them, and you will need to remove the total row. Make sure that the columns containing votes are numeric.

```{r}
download.file ("https://elections.utah.gov/Media/Default/2018%20Election/2018%20General%20Election%20Canvass.xlsx", "2018_results_xlsx")
```

```{r}
utah_2018_results <- read_excel("2018_results_xlsx")

utah_2018_results <- read_excel("2018_results_xlsx", sheet= 2)
```

```{r}
senate_18_results <- utah_2018_results[[1]] %>%
    slice(-2, -33, -34) 
```

```{r}
# Standardize column headers, remove last row
senate_18_results <- utah_2018_results %>%
    slice(-1, -33, -34) %>%
  clean_names() %>%
  rename(county = 1, aalders = 2, bowden = 3, mccandless = 4, wilson = 5, romney = 6, fitzgerald = 7, reeve = 8, reiksthegn = 9, korb = 10, jackson = 11, judy = 12, jensen = 13) %>%
  mutate(aalders = as.numeric(gsub(",","", aalders))) %>%
  mutate(bowden = as.numeric(gsub(",","", bowden))) %>%
  mutate(mccandless  = as.numeric(gsub(",","", mccandless))) %>%
  mutate(wilson = as.numeric(gsub(",","", wilson))) %>%
  mutate(romney = as.numeric(gsub(",","", romney))) %>%
  mutate(fitzgerald = as.numeric(gsub(",","", fitzgerald))) %>%
  mutate(reeve = as.numeric(gsub(",","", reeve))) %>%
  mutate(reiksthegn = as.numeric(gsub(",","", reiksthegn))) %>%
  mutate(korb = as.numeric(gsub(",","", korb))) %>%
  mutate(jackson = as.numeric(gsub(",","", jackson))) %>%
  mutate(judy = as.numeric(gsub(",","", judy))) %>%
  mutate(jensen = as.numeric(gsub(",","", jensen)))
# show the dataframe
senate_18_results
```

```{r}
senate_18_results <- senate_18_results %>%
  slice(-1)

senate_results
```


Finally, join the two dataframes together:

**Task** Join the 2022 and 2018 results into a single dataframe.

```{r}
joined_results <- inner_join(senate_results, senate_18_results, by=c("county" = "county"))
```

## Questions

**Q1.** Calculate the difference in votes between Evan McMullin and Jenny Wilson and save it your combined dataframe. Write up some sentences that could go in a story describing where McMullin outperformed Wilson and where he didn't. Mention the margins and describe the counties you mention (location, population or another factor, such as 2020 presidential vote).

**A1.** McMullin did better than Wilson in all but one county, San Juan, which has fewer than 15,000 people. In particular, McMullin did much better in Utah County, which includes Brigham Young University. McMullin got within 4,000 votes of Joe Biden's total in 2018 here.

```{r}
wilson_mcmullin_diff <- joined_results %>%
  select(county, mcmullin, wilson) %>%
  mutate(diffr= mcmullin - wilson) 
```

**Q2** Calculate the difference in votes between Mike Lee and Mitt Romney and save it your combined dataframe. Write up some sentences that could go in a story describing where Romney outperformed Lee and where he didn't. Mention the margins and describe the counties you mention (location, population or another factor).

**A2** Romney got more votes in 13 of Utah's 29 counties, and in particular Salt Lake and Davis counties. In the counties where Lee outperformed Romney, the margin was a matter of less than a thousand votes in all but one case. Lee's best performance relative to Romney was in Washington County, a reliably conservative county.

```{r}
lee_romney_diff <- joined_results %>%
  select(county, lee, romney) %>%
  mutate(diffr= lee - romney) 
```

**Q3** Sen. Ben Cardin, D-Maryland, has posted hundreds of press releases at https://www.cardin.senate.gov/?post_type=press-releases. It would be great to have all of them in a dataframe that has the following columns: date, title and url.

To do this, you will need to scrape the page's html and save that to a variable, and separately use that variable to then extract the dates, titles and urls into separate dataframes using html_elements(). The function `html_text()` pulls out the contents of a tag, but for urls we want the HTML attribute. Rvest gives you a way to extract the URL from a link; google to find out what it is.

At the end, you'll have three dataframes that you want to combine into a single dataframe. When we want to combine the rows of identical dataframes, we used `bind_rows()`. There's an alternative you can use to do the same for combining columns, and it works the same way.

When you're done, rename the columns so they make sense, then make sure the date column is an actual date.

Finally, tell me what questions you could ask of this data. Be creative.

**A3**
I am curious about the 10 press releases that mentioned WMATA in the title. They almost all focus on safety improvements, with a few announcing funds for those improvements. I would be interested in a story on why there's so many safety pushes and if there are any out of the ordinary issues, or if it's just general push to make sure the public transit stays safe. I would also be interested in knowing about Cardin's relationship with WMATA. Is he putting out all of these releases like every other local politician or he is more actively involved in some ways?

On a larger note, I think he could be interesting to search the data for a few key terms such railway, strike, safety, covid-19, etc. to see how often Cardin is putting out releases on certain things and if there's anything in particular he might have a focus on that I might not know as someone not from the area. 
, 
```{r}
cardin_url <- "https://www.cardin.senate.gov/?post_type=press-releases"
```

```{r}
cardin_results <- cardin_url %>%
  read_html()

# show the result
cardin_results
```

```{r}
dates <- cardin_results %>% 
  html_elements('h5') %>% 
  html_text() %>% 
  as_tibble()
```

```{r}
titles <- cardin_results %>% 
  html_elements('h3') %>% 
  html_text() %>% 
  as_tibble()
```

```{r}
urls <- cardin_results %>% 
  html_element('h3 a') %>%
  html_attr('href') %>% 
  as_tibble()
```

```{r}
totals <- bind_cols(dates, titles, urls)
```

```{r}
totals_cleaned <- totals %>% 
  clean_names() %>% 
  rename(date = 1, title = 2, url= 3)
```

```{r}
totals_cleaned <- totals_cleaned %>%
  mutate(date=mdy(date))
```

